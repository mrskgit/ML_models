{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель:\n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "\n",
    "### Шаги по выполнению проекта\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Векторизация текстов.\n",
    "2. Обучение разныех модели. \n",
    "3. Выводы.\n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "import transformers\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим максимальную длину строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'] = df['text'].apply(lambda x: len(x))\n",
    "df['len'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на соотношение положительных и отрицательных значений целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас сильный дисбаланс целевых признаков. При плохом качестве модели можно будет попробовать сделать upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения моделей следует векторизировать текст. Попробуем два способа векторизации: TF-IDF из библиотеки sklearn и модель BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала лемматизируем тексты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим объект лемматизатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая сначала токенизирует текст, а затем лемматизирует его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    # токенизируем текст:\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    \n",
    "    # лемматизируем каждое слово\n",
    "    lemmatize = []\n",
    "    for word in tokenized:\n",
    "        stem_word = stemmer.stem(word)\n",
    "        lemmatize.append(stem_word)\n",
    "    \n",
    "    # собираем лемматизированные слова в строку\n",
    "    lemmatize = ' '.join(lemmatize)\n",
    "    return lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 59s, sys: 84 ms, total: 4min 59s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>d'aww ! he match this background colour i 'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>hey man , i 'm realli not tri to edit war . it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>622</td>\n",
       "      <td>`` more i ca n't make ani real suggest on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>you , sir , are my hero . ani chanc you rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>`` : : : : : and for the second time of ask , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>you should be asham of yourself that is a horr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>spitzer umm , there no actual articl for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>and it look like it was actual you who put on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>`` and ... i realli do n't think you understan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0  264   \n",
       "1       D'aww! He matches this background colour I'm s...      0  112   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0  233   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0  622   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   67   \n",
       "...                                                   ...    ...  ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0  295   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   99   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   81   \n",
       "159569  And it looks like it was actually you who put ...      0  116   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0  189   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       explan whi the edit made under my usernam hard...  \n",
       "1       d'aww ! he match this background colour i 'm s...  \n",
       "2       hey man , i 'm realli not tri to edit war . it...  \n",
       "3       `` more i ca n't make ani real suggest on impr...  \n",
       "4       you , sir , are my hero . ani chanc you rememb...  \n",
       "...                                                   ...  \n",
       "159566  `` : : : : : and for the second time of ask , ...  \n",
       "159567  you should be asham of yourself that is a horr...  \n",
       "159568  spitzer umm , there no actual articl for prost...  \n",
       "159569  and it look like it was actual you who put on ...  \n",
       "159570  `` and ... i realli do n't think you understan...  \n",
       "\n",
       "[159571 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст от лишних символов. Оставим только английский буквы. Для этого напишем функцию clear_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    new_text = re.sub(r'[^a-zA-Z\\' ]', '', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим столбец с текстом, очищенным от лишних символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 8 ms, total: 1.53 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['clear_text'] = df['lemm_text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем длину получившихся строк (она нам понадобиться в дальнейшем при подготовке данных для модели BERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clear_len'] = df['clear_text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>clear_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>d'aww ! he match this background colour i 'm s...</td>\n",
       "      <td>d'aww  he match this background colour i 'm se...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>hey man , i 'm realli not tri to edit war . it...</td>\n",
       "      <td>hey man  i 'm realli not tri to edit war  it '...</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>622</td>\n",
       "      <td>`` more i ca n't make ani real suggest on impr...</td>\n",
       "      <td>more i ca n't make ani real suggest on improv...</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>you , sir , are my hero . ani chanc you rememb...</td>\n",
       "      <td>you  sir  are my hero  ani chanc you rememb wh...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>`` : : : : : and for the second time of ask , ...</td>\n",
       "      <td>and for the second time of ask  when you...</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>you should be asham of yourself that is a horr...</td>\n",
       "      <td>you should be asham of yourself that is a horr...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>spitzer umm , there no actual articl for prost...</td>\n",
       "      <td>spitzer umm  there no actual articl for prosti...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>and it look like it was actual you who put on ...</td>\n",
       "      <td>and it look like it was actual you who put on ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>`` and ... i realli do n't think you understan...</td>\n",
       "      <td>and  i realli do n't think you understand  i ...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0  264   \n",
       "1       D'aww! He matches this background colour I'm s...      0  112   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0  233   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0  622   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   67   \n",
       "...                                                   ...    ...  ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0  295   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   99   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   81   \n",
       "159569  And it looks like it was actually you who put ...      0  116   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0  189   \n",
       "\n",
       "                                                lemm_text  \\\n",
       "0       explan whi the edit made under my usernam hard...   \n",
       "1       d'aww ! he match this background colour i 'm s...   \n",
       "2       hey man , i 'm realli not tri to edit war . it...   \n",
       "3       `` more i ca n't make ani real suggest on impr...   \n",
       "4       you , sir , are my hero . ani chanc you rememb...   \n",
       "...                                                   ...   \n",
       "159566  `` : : : : : and for the second time of ask , ...   \n",
       "159567  you should be asham of yourself that is a horr...   \n",
       "159568  spitzer umm , there no actual articl for prost...   \n",
       "159569  and it look like it was actual you who put on ...   \n",
       "159570  `` and ... i realli do n't think you understan...   \n",
       "\n",
       "                                               clear_text  clear_len  \n",
       "0       explan whi the edit made under my usernam hard...        231  \n",
       "1       d'aww  he match this background colour i 'm se...         93  \n",
       "2       hey man  i 'm realli not tri to edit war  it '...        210  \n",
       "3        more i ca n't make ani real suggest on improv...        556  \n",
       "4       you  sir  are my hero  ani chanc you rememb wh...         65  \n",
       "...                                                   ...        ...  \n",
       "159566        and for the second time of ask  when you...        270  \n",
       "159567  you should be asham of yourself that is a horr...         81  \n",
       "159568  spitzer umm  there no actual articl for prosti...         72  \n",
       "159569  and it look like it was actual you who put on ...        111  \n",
       "159570   and  i realli do n't think you understand  i ...        180  \n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим обучающие и целевые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['clear_text']\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_train,\n",
    " features_test,\n",
    " target_train,\n",
    " target_test) = train_test_split(features, target, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим соотношение положительных и отрицательных ответов в обучающей и тестовой выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(121)\n",
    "plt.pie(target_train.value_counts(), labels=target_train.value_counts().index)\n",
    "plt.title('train')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.pie(target_test.value_counts(), labels=target_train.value_counts().index)\n",
    "plt.title('test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "соотношение положительных и отрицательных ответов в обучающей и тестовой выборках примерно одинаковое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем текст. При векторизации уберем из текста стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо стоп-слов исключим из текстов слишком редкие и слишком частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.34 s, sys: 144 ms, total: 8.48 s\n",
      "Wall time: 8.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_train = count_tf_idf.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 21974)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    114756\n",
       "1     12900\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915, 21974)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим несколько разных моделей и посмотрим на метрику f1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 2min 4s, total: 5min 14s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegressionCV(class_weight='balanced', \n",
    "                                cv=2,\n",
    "                                random_state=12,\n",
    "                                scoring='f1').fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим среднее значение f1, которую показала логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032598430811878"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores = []\n",
    "for i in model_lr.scores_[1]:\n",
    "    lr_scores.append(i.mean())\n",
    "lr_scores = np.array(lr_scores).mean()\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для остальных моделей напишем функцию для подобора гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_best_params(model, param_grid):\n",
    "    grid = GridSearchCV(estimator=model,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='f1',\n",
    "                        cv=3)\n",
    "    grid.fit(features_train, target_train)\n",
    "    print('Лучшие параметры: {}'.format(grid.best_params_))\n",
    "    print('F1: {:.2f}'.format(grid.best_score_))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры и протестируем еще несколько моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'learning_rate': 1.0}\n",
      "F1: 0.69\n",
      "CPU times: user 3min 54s, sys: 524 ms, total: 3min 55s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_abc = AdaBoostClassifier(random_state=12)\n",
    "param_abc = {'learning_rate' : [1.0, 0.5]}\n",
    "model_abc = search_best_params(model_abc, param_abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 200}\n",
      "F1: 0.62\n",
      "CPU times: user 1min 55s, sys: 0 ns, total: 1min 55s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rfc = RandomForestClassifier(class_weight='balanced', random_state=12)\n",
    "\n",
    "params_rfc = {'max_depth' : [100, 200]}\n",
    "\n",
    "model_rfc = search_best_params(model_rfc, params_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light GBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 100}\n",
      "F1: 0.69\n",
      "CPU times: user 4min 45s, sys: 808 ms, total: 4min 46s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(random_state=12, n_estimators=30)\n",
    "\n",
    "params_lgb = {'max_depth' : [100, 200]}\n",
    "\n",
    "model_lgb = search_best_params(model_lgb, params_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем полученные результаты в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.703260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LGBClassifier</td>\n",
       "      <td>0.690652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.686777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.623598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  f1_score\n",
       "0  LogisticRegressionCV  0.703260\n",
       "3         LGBClassifier  0.690652\n",
       "1              AdaBoost  0.686777\n",
       "2          RandomForest  0.623598"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(data=[['LogisticRegressionCV', lr_scores],\n",
    "                           ['AdaBoost', model_abc.best_score_],\n",
    "                           ['RandomForest', model_rfc.best_score_],\n",
    "                           ['LGBClassifier', model_lgb.best_score_]],\n",
    "                      columns=['Model', 'f1_score'])\n",
    "result.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат показала логистическая регрессия. Проверим качество модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.76\n"
     ]
    }
   ],
   "source": [
    "print('F1 = {:.2f}'.format(f1_score(model_lr.predict(features_test), target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация через BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем векторизировать текст с использованием модели BERT. Поскольку она очень требовательна к ресурсам, протстируем ее на небольшой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала уберем из нашего датафрейма все записи длинне 512 символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = df[df['len'] < 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем сэмпл в 500 записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = df_bert.sample(n=500, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.872\n",
       "1    0.128\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим целевой признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bert = df_bert['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем наши тексты. Для этого инициализируем токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(vocab_file='vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перобразуем текст в токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 484 ms, sys: 0 ns, total: 484 ms\n",
      "Wall time: 488 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = df_bert['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выровняем длины векторов. Для этого определим максимальную длину векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = pd.Series(len(x) for x in tokenized).max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим маску для значимых токенов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_json_file('bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_bert = transformers.BertModel.from_pretrained('pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст в эмбеддинги. Для этого сделаем цикл по батчам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83b91d6008f4a8d981c55607895c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 10min 24s, sys: 1min 7s, total: 11min 31s\n",
      "Wall time: 11min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size * i : batch_size * (i + 1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size * i : batch_size * (i + 1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model_bert(batch, attention_mask = attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].numpy())\n",
    "\n",
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bert_features_train,\n",
    " bert_features_test,\n",
    " bert_target_train,\n",
    " bert_target_test) = train_test_split(features_bert, target_bert, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.24 s, sys: 4 s, total: 7.24 s\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_bert = LogisticRegressionCV(class_weight='balanced', \n",
    "                               cv=2,\n",
    "                               random_state=12,\n",
    "                               scoring='f1').fit(bert_features_train, bert_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5706417786587057"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_scores = []\n",
    "for i in lr_bert.scores_[1]:\n",
    "    bert_scores.append(i.mean())\n",
    "bert_scores = np.array(bert_scores).mean()\n",
    "bert_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.69\n"
     ]
    }
   ],
   "source": [
    "print('F1 = {:.2f}'.format(f1_score(lr_bert.predict(bert_features_test), bert_target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовлена модель предсказания тональной окраски текста комментариев.\n",
    "\n",
    "\n",
    "Подготовка эбеддингов выполнена с использованием TF-IDF.\n",
    "\n",
    "\n",
    "Для предсказания тональной окраски текста протестировано несколько моделей: LogisticRegressionCV, AdaBoost, RandomForest, LGBClassifier. Модели обучались на обучающей выборки с использованием кросс-валидации (cv=3).\n",
    "\n",
    "\n",
    "Лучшую метрику на кросс-валидации показала модель LogisticRegressionCV с f1 = 0.7.\n",
    "\n",
    "\n",
    "На тестовой выборке модель показала f1 = 0.76.\n",
    "\n",
    "\n",
    "Дя экономии времени обучения на небольшой выборке (500 объектов) протестирована векторизация текста с использованием BERT. Модель LogisticRegressionCV на тестовой выборке показала f1 = 0.69. Неплохой результат, учитывая небольшую обучающую выборку. При обучении на полном датасете вектоизация с помощью BERT скорее всего показала бы лучшие результаты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
